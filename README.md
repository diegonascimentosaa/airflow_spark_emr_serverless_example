# ðŸš€ EMR Serverless Simulation

Este projeto Ã© uma **simulaÃ§Ã£o local de um ambiente de Big Data** robusto. O objetivo Ã© demonstrar uma orquestraÃ§Ã£o de ETL utilizando **Apache Airflow** para gerenciar containers efÃªmeros (serverless) que executam jobs **Apache Spark**.

A arquitetura simula o funcionamento de um serviÃ§o como o **AWS EMR Serverless**: o Airflow inicia um container Spark sob demanda, executa o processamento de dados e, ao final, o container Ã© encerrado automaticamente, otimizando o uso de recursos.

---

## ðŸ—ï¸ Arquitetura de Dados

O projeto segue a **Arquitetura MedalhÃ£o (Medallion Architecture)**, na qual os dados fluem por camadas de refinamento dentro de um Data Lake simulado (diretÃ³rio local `/data`).

### ðŸ”„ Pipeline de Processamento (`steps.py`)

1. **Ingestion (Transient)**
   Consome dados de uma API externa e salva os dados brutos no formato **JSON**.

2. **Raw (Bronze)**
   LÃª os arquivos JSON da camada de ingestÃ£o e converte os dados para o formato **Parquet** (colunar).

3. **Trusted (Silver)**
   LÃª os dados da camada Raw e realiza **tipagem, padronizaÃ§Ã£o e limpezas**.

4. **Refined (Gold)**
   Realiza **joins** entre as tabelas tratadas e gera um **relatÃ³rio final agregado**.

---

## ðŸ› ï¸ Tecnologias Utilizadas

* **Apache Airflow** - OrquestraÃ§Ã£o e agendamento de pipelines
* **Apache Spark (PySpark)** - Processamento distribuÃ­do
* **Docker & Docker Compose** - ContainerizaÃ§Ã£o e infraestrutura
* **Telegram Bot** - Alertas e monitoramento de execuÃ§Ã£o
* **Python** - ImplementaÃ§Ã£o dos scripts de ETL

---

## âš™ï¸ InstalaÃ§Ã£o e ExecuÃ§Ã£o

Siga os passos abaixo **na ordem indicada** para configurar e executar o ambiente local.

---

### 1ï¸âƒ£ Ajuste de PermissÃµes do Docker (Linux / WSL)

Para que o Airflow consiga criar containers Spark dinamicamente, Ã© necessÃ¡rio ajustar o grupo de usuÃ¡rios do Docker.

1. Descubra o **ID do grupo Docker** executando no terminal:

```bash
getent group docker | cut -d: -f3
```

> O resultado serÃ¡ um nÃºmero, por exemplo: `999`, `998` ou `130`.

2. Abra o arquivo `docker-compose.yaml`, localize o serviÃ§o `airflow` e ajuste a propriedade `group_add` com o ID encontrado:

```yaml
services:
  airflow:
    group_add:
      - "999"  # Substitua pelo ID do grupo Docker da sua mÃ¡quina
```

---

### 2ï¸âƒ£ PreparaÃ§Ã£o do Data Lake

Crie o diretÃ³rio local que simula o Data Lake e conceda permissÃ£o de escrita para os containers.

```bash
mkdir -p data
chmod 777 data
```

---

### 3ï¸âƒ£ Build da Imagem Spark

O Airflow executa os jobs Spark utilizando a imagem **`projeto-spark-custom`**. Essa imagem **precisa ser criada manualmente** antes de subir o ambiente.

```bash
docker build -t projeto-spark-custom:latest ./docker/spark
```

---

### 4ï¸âƒ£ Executar o Ambiente

Inicie todos os serviÃ§os de orquestraÃ§Ã£o:

```bash
docker-compose up
```

ApÃ³s a inicializaÃ§Ã£o, acesse a interface do Airflow:

* **URL:** [http://localhost:8080](http://localhost:8080)
* **UsuÃ¡rio:** `admin`
* **Senha:** `AparecerÃ¡ ao final da compilaÃ§Ã£o do docker-compose`

---

## ðŸ”” ConfiguraÃ§Ã£o de NotificaÃ§Ãµes (Telegram)

O projeto possui integraÃ§Ã£o com **Telegram** para envio de alertas de sucesso ou falha das DAGs.

---

### ðŸ“Œ Parte A â€” Criar o Bot

1. No Telegram, converse com o bot **@BotFather**.
2. Envie o comando:

```text
/newbot
```

3. Guarde o **Token** gerado.
4. Envie uma mensagem (ex: "Oi") para o seu novo bot para habilitar o envio de mensagens.

---

### ðŸ“Œ Parte B â€” Configurar o CÃ³digo

No arquivo `dags/base_dag.py`, atualize a variÃ¡vel:

```python
TELEGRAM_CHAT_ID = "SEU_CHAT_ID_AQUI"
```

> ðŸ’¡ **Dica:** Descubra seu Chat ID enviando `/start` para o bot **@userinfobot**.

---

### ðŸ“Œ Parte C â€” Criar a ConexÃ£o no Airflow

1. Acesse o Airflow
2. VÃ¡ em **Admin â†’ Connections**
3. Clique em **+ (Create)**
4. Preencha os campos:

| Campo               | Valor                       |
| ------------------- | --------------------------- |
| **Connection Id**   | `telegram_default`          |
| **Connection Type** | `Telegram`                  |
| **Password**        | Token gerado pelo BotFather |

5. Clique em **Save**